# -*- coding: utf-8 -*-
"""19201055car_price_sklearn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mFqGVQaqTKnMzMEJTKVf62Atfk43q7RI
"""

from google.colab import drive
drive.mount("/content/drive", force_remount=True)
from typing_extensions import Text
data = pd.read_csv('/content/drive/MyDrive/ai/CarPrice_Assignment.csv')
df = data.copy()

df.head()

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import seaborn as sns
import matplotlib.pyplot as plt


from sklearn.tree import DecisionTreeRegressor
from sklearn import datasets

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

df.columns

cat_col = df.select_dtypes(include=['object']).columns
num_col = df.select_dtypes(exclude=['object']).columns

cat_col

num_col

df.head()

df.shape

df.dtypes

df.info()

df.describe().T

plt.figure(figsize=(15,10))
sns.histplot(data['horsepower'],color="y")
plt.title('Car horsepower Distribution Plot')

plt.figure(figsize=(15,10))
sns.histplot(data['curbweight'],color="y")
plt.title('Car curbweight Distribution Plot')

plt.figure(figsize=(15,10))
sns.histplot(data['price'],color="y")

plt.figure(figsize=(15,10))
sns.histplot(data['enginesize'],color="y")

sns.scatterplot(x="enginesize", y="price", data=df,color='y');

sns.scatterplot(x="horsepower", y="price", data=df,color='g');

sns.scatterplot(x="curbweight", y="price", data=df,color='c');

df.corr()

#sns.heatmap(df[num_col].corr(),annot = True);

y = df.price
print(y)

df_features = ['curbweight','enginesize','horsepower']

X = df[df_features]

X.describe()

df_model = DecisionTreeRegressor(random_state = 1)

# fit
df_model.fit(X,y)

print(X.head())
print(df_model.predict(X.head()))

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=101)

from sklearn.linear_model import LinearRegression

lm = LinearRegression()

lm.fit(X_train,y_train)

print(lm.intercept_)

coeff_df = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])
coeff_df

predictions = lm.predict(X_test)

plt.scatter(y_test,predictions)

sns.distplot((y_test-predictions),bins=50);

from sklearn.metrics import mean_squared_error
mean_squared_error(y_test, predictions)

print("Coefficients: \n", lm.coef_)
# Mean Squared Error
print("Mean Squared Error: %.2f" %np.mean((lm.predict(X_test)-y_test)**2))
# Explained Variance Score : 1 is perfect prediction
print("Variance score: %.2f" %lm.score(X_test, y_test))